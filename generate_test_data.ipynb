{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dff410c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tweepy\n",
    "from textblob import TextBlob\n",
    "import json\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4207caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEARER_TOKEN = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2db8d657",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterClient(object):\n",
    "    '''\n",
    "    Generic Twitter Class for sentiment analysis.\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Class constructor or initialization method.\n",
    "        '''\n",
    "#         # attempt authentication\n",
    "#         try:\n",
    "#             self.auth = tweepy.OAuth2BearerHandler(BEARER_TOKEN)\n",
    "\n",
    "#             # create tweepy API object to fetch tweets\n",
    "#             self.api = tweepy.API(self.auth)\n",
    "#         except:\n",
    "#             print(\"Error: Authentication Failed\")\n",
    "        self.client = tweepy.Client(bearer_token=BEARER_TOKEN)\n",
    "\n",
    "    def clean_tweet(self, tweet):\n",
    "        '''\n",
    "        Utility function to clean tweet text by removing links, special characters\n",
    "        using simple regex statements.\n",
    "        '''\n",
    "        return ' '.join(\n",
    "            re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t]) |(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "\n",
    "    def get_tweet_sentiment(self, tweet):\n",
    "        '''\n",
    "        Utility function to classify sentiment of passed tweet\n",
    "        using textblob's sentiment method\n",
    "        '''\n",
    "        # create TextBlob object of passed tweet text\n",
    "        analysis = TextBlob(self.clean_tweet(tweet))\n",
    "        # set sentiment\n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            return 'positive'\n",
    "        elif analysis.sentiment.polarity == 0:\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            return 'negative'\n",
    "\n",
    "    def get_tweets(self, query, count=50, lang=\"en\"):\n",
    "        '''\n",
    "        Main function to fetch tweets and parse them.\n",
    "        '''\n",
    "        # empty list to store parsed tweets\n",
    "        tweets = []\n",
    "\n",
    "        try:\n",
    "            # call twitter api to fetch tweets\n",
    "#             fetched_tweets = self.api.search_tweets(q=query, lang=lang, locale=\"usa\", count=count, tweet_mode=\"extended\")\n",
    "            fetched_tweets = self.client.search_recent_tweets(query=query, \n",
    "                              tweet_fields=['public_metrics', 'context_annotations', 'entities', 'geo', 'lang', 'in_reply_to_user_id',\n",
    "                                           'referenced_tweets', 'source', 'text', 'withheld', 'attachments'\n",
    "                                           ],\n",
    "                                expansions=['attachments.media_keys', 'referenced_tweets.id', 'author_id', 'geo.place_id'],\n",
    "                                media_fields=['type', 'duration_ms', 'preview_image_url'],\n",
    "                             )\n",
    "            # parsing tweets one by one\n",
    "            for tweet in fetched_tweets.data:\n",
    "                # empty dictionary to store required params of a tweet\n",
    "                parsed_tweet = {}\n",
    "\n",
    "                # saving text of tweet\n",
    "                parsed_tweet = tweet.data\n",
    "#                 parsed_tweet['id'] = tweet.id\n",
    "#                 parsed_tweet['text'] = tweet.text\n",
    "#                 parsed_tweet['attachments'] = tweet.attachments\n",
    "#                 parsed_tweet['public_metrics'] = tweet.public_metrics\n",
    "# #                 parsed_tweet['referenced_tweets'] = tweet.referenced_tweets\n",
    "#                 parsed_tweet['author_id'] = tweet.author_id\n",
    "                \n",
    "                tweets.append(parsed_tweet)\n",
    "\n",
    "            # return parsed tweets\n",
    "            return tweets\n",
    "\n",
    "        except tweepy.TweepyException as e:\n",
    "            # print error (if any)\n",
    "            print(\"Error : \" + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a8b38d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # creating object of TwitterClient Class\n",
    "    api = TwitterClient()\n",
    "    # calling function to get tweets\n",
    "    tweets = api.get_tweets(query='(#pepsi OR #coke OR #cocacola) -is:retweet', count=100)\n",
    "#     json.dumps(tweets, ensure_ascii=False).encode('utf8')\n",
    "#     with codecs.open(\"test.json\", 'w') as fp:\n",
    "#         fp.write(json.dumps(tweets, ensure_ascii=False).encode('utf8'))\n",
    "    with open('test.json', 'w', encoding='utf8') as json_file:\n",
    "        json.dump(tweets, json_file, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1edc0e7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calling main function\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25128fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
